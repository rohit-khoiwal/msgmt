{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZS39YrCcAjGD",
        "outputId": "48db36bc-b62e-453b-fd46-d3ee5eef5233",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZS39YrCcAjGD",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Github/"
      ],
      "metadata": {
        "id": "uwcI-TsBAh_I",
        "outputId": "87df30bb-6342-49dc-c81e-313d12367ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uwcI-TsBAh_I",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull https://github.com/rohit-khoiwal-30/msgmt.git"
      ],
      "metadata": {
        "id": "Jbsk8f1DBIY_",
        "outputId": "3a050cf2-8583-4b4f-f304-5a0e5f980186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Jbsk8f1DBIY_",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/21)\u001b[K\rremote: Counting objects:   9% (2/21)\u001b[K\rremote: Counting objects:  14% (3/21)\u001b[K\rremote: Counting objects:  19% (4/21)\u001b[K\rremote: Counting objects:  23% (5/21)\u001b[K\rremote: Counting objects:  28% (6/21)\u001b[K\rremote: Counting objects:  33% (7/21)\u001b[K\rremote: Counting objects:  38% (8/21)\u001b[K\rremote: Counting objects:  42% (9/21)\u001b[K\rremote: Counting objects:  47% (10/21)\u001b[K\rremote: Counting objects:  52% (11/21)\u001b[K\rremote: Counting objects:  57% (12/21)\u001b[K\rremote: Counting objects:  61% (13/21)\u001b[K\rremote: Counting objects:  66% (14/21)\u001b[K\rremote: Counting objects:  71% (15/21)\u001b[K\rremote: Counting objects:  76% (16/21)\u001b[K\rremote: Counting objects:  80% (17/21)\u001b[K\rremote: Counting objects:  85% (18/21)\u001b[K\rremote: Counting objects:  90% (19/21)\u001b[K\rremote: Counting objects:  95% (20/21)\u001b[K\rremote: Counting objects: 100% (21/21)\u001b[K\rremote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 14 (delta 10), reused 5 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (14/14), done.\n",
            "From https://github.com/rohit-khoiwal-30/msgmt\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Updating a4e19c9..283c440\n",
            "Fast-forward\n",
            " augment_train.csv    | 16410 \u001b[32m++++++++++++++++++++++\u001b[m\u001b[31m----------------------\u001b[m\n",
            " bertEUCL.ipynb       |   198 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " evaluation.csv       | 18062 \u001b[32m++++++++++++++++++++++++\u001b[m\u001b[31m-------------------------\u001b[m\n",
            " preprocess.ipynb     |  2414 \u001b[32m+++\u001b[m\u001b[31m----\u001b[m\n",
            " useEUCL.ipynb        |   398 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " useTripleLoss .ipynb |   677 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 6 files changed, 19388 insertions(+), 18771 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "31f1d5b5",
      "metadata": {
        "id": "31f1d5b5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a32b3efc",
      "metadata": {
        "id": "a32b3efc"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"augment_train.csv\")\n",
        "df_test = pd.read_csv(\"evaluation.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "60970f05",
      "metadata": {
        "id": "60970f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783dc765-108a-43a3-a19a-6ae511e1cb53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-self-attention\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (1.21.6)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=4f2a47e570145780a39904a99fd61e11889c102cae6f2cff0fddf42c0450145c\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.51.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as tfl\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "try:\n",
        "    import tensorflow_hub as hub\n",
        "except ModuleNotFoundError:\n",
        "    %pip install tensorflow_hub\n",
        "    import tensorflow_hub as hub\n",
        "    \n",
        "try:\n",
        "    from keras_self_attention import SeqSelfAttention\n",
        "except ModuleNotFoundError:\n",
        "    %pip install keras-self-attention\n",
        "    from keras_self_attention import SeqSelfAttention\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# %pip install -q transformers\n",
        "# %pip install -q -U tensorflow-text\n",
        "# %pip install -q tf-models-official==2.7.0\n",
        "\n",
        "import math as m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "39e6d422",
      "metadata": {
        "id": "39e6d422"
      },
      "outputs": [],
      "source": [
        "huburl = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
        "fine_tuned_module_object = hub.load(huburl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "722fb270",
      "metadata": {
        "id": "722fb270"
      },
      "outputs": [],
      "source": [
        "def gen_random_batch(in_groups, batch_halfsize = 8):\n",
        "    text_batch, reason_batch, y_hat = [], [], []\n",
        "    all_groups = list(range(in_groups[0].shape[0]))\n",
        "    for match_group in [True, False]:\n",
        "        group_idx = np.random.choice(all_groups, size = batch_halfsize)\n",
        "        text_batch += [in_groups[0][c_idx] for c_idx in group_idx]\n",
        "        if match_group:\n",
        "            b_group_idx = group_idx\n",
        "            y_hat += [1]*batch_halfsize\n",
        "        else:\n",
        "            # anything but the same group\n",
        "            non_group_idx = [np.random.choice([i for i in all_groups if i!=c_idx]) for c_idx in group_idx] \n",
        "            b_group_idx = non_group_idx\n",
        "            y_hat += [0]*batch_halfsize\n",
        "            \n",
        "        reason_batch += [in_groups[1][c_idx] for c_idx in b_group_idx]\n",
        "            \n",
        "    return np.stack(text_batch, 0), np.stack(reason_batch, 0), np.stack(y_hat, 0)\n",
        "\n",
        "def siam_gen(in_groups, batch_size = 32):\n",
        "    while True:\n",
        "        text_stack, reason_stack, y_hatstack = gen_random_batch(in_groups, batch_size//2)\n",
        "        yield [text_stack, reason_stack], y_hatstack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "90747622",
      "metadata": {
        "id": "90747622"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    results = (y_pred >= 0.5).astype(int).squeeze()\n",
        "    return np.mean([y_true == results])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8010b51c",
      "metadata": {
        "id": "8010b51c"
      },
      "outputs": [],
      "source": [
        "def encoder1(name):\n",
        "    inputs = Input(shape=(), dtype=tf.string)\n",
        "\n",
        "    shared_embedding_layer = hub.KerasLayer(fine_tuned_module_object, trainable=True, name=name)\n",
        "    embedding_output= shared_embedding_layer(inputs)\n",
        "    a = tfl.Dropout(0.3)(embedding_output)\n",
        "    a = tfl.Dense(128, activation=\"linear\", kernel_regularizer=l2(1e-3))(a)\n",
        "    a = tfl.BatchNormalization()(a)\n",
        "    a = tfl.Activation('relu')(a)\n",
        "    a = tfl.Dense(64, activation=\"linear\", kernel_regularizer=l2(1e-3))(a)\n",
        "    a = tfl.BatchNormalization()(a)\n",
        "    a = tfl.Activation('relu')(a)\n",
        "    outputs = tfl.Dense(32, activation=\"linear\", kernel_regularizer=l2(1e-3))(a)\n",
        "    a = tfl.BatchNormalization()(a)\n",
        "    outputs = tfl.Activation('relu')(a)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "def encoder2(name):\n",
        "    inputs = Input(shape=(), dtype=tf.string)\n",
        "\n",
        "    shared_embedding_layer = hub.KerasLayer(fine_tuned_module_object, trainable=True, name=name)\n",
        "    embedding_output= shared_embedding_layer(inputs)\n",
        "    a = tfl.Dropout(0.3)(embedding_output)\n",
        "    a = tfl.Dense(64, activation=\"linear\", kernel_regularizer=l2(1e-3))(a)\n",
        "    a = tfl.BatchNormalization()(a)\n",
        "    a = tfl.Activation('relu')(a)\n",
        "    outputs = tfl.Dense(32, activation=\"linear\", kernel_regularizer=l2(1e-3))(a)\n",
        "    a = tfl.BatchNormalization()(a)\n",
        "    outputs = tfl.Activation('relu')(a)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "05b1e776",
      "metadata": {
        "id": "05b1e776"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    #textEncoder\n",
        "    inputText = Input(shape=(), dtype=tf.string)\n",
        "    text_embedd = encoder1(\"textUSEencoder\")(inputText)\n",
        "\n",
        "    #reasonEncoder\n",
        "    inputReason = Input(shape=(), dtype=tf.string)\n",
        "    reason_embedd = encoder2(\"reasonUSEencoder\")(inputReason)\n",
        "\n",
        "    combined_features = tfl.concatenate([text_embedd, reason_embedd], name = 'merge_features')\n",
        "    print(combined_features.shape)\n",
        "    combined_features = tfl.Dropout(0.2)(combined_features)\n",
        "    combined_features = tfl.Dense(16, activation = 'linear', kernel_regularizer=l2(1e-3))(combined_features)\n",
        "    combined_features = tfl.BatchNormalization()(combined_features)\n",
        "    combined_features = tfl.Activation('relu')(combined_features)\n",
        "    combined_features = tfl.Dense(4, activation = 'linear', kernel_regularizer=l2(1e-3))(combined_features)\n",
        "    combined_features = tfl.BatchNormalization()(combined_features)\n",
        "    combined_features = tfl.Activation('relu')(combined_features)\n",
        "    combined_features = tfl.Dense(1, activation = 'sigmoid')(combined_features)\n",
        "    \n",
        "    model = Model(inputs = [inputText, inputReason], outputs = [combined_features], name=\"uceModel\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "aa8fbcab",
      "metadata": {
        "id": "aa8fbcab",
        "outputId": "7625f8c8-af88-4696-aaa7-de01dbc99710",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 128)\n"
          ]
        }
      ],
      "source": [
        "model = get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5f2012db",
      "metadata": {
        "id": "5f2012db",
        "outputId": "c443ac60-e00f-4fbe-86be-19c6ce64dfe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"uceModel\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_2 (Functional)           (None, 64)           256872768   ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " model_3 (Functional)           (None, 64)           256831168   ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " merge_features (Concatenate)   (None, 128)          0           ['model_2[0][0]',                \n",
            "                                                                  'model_3[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 128)          0           ['merge_features[0][0]']         \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 16)           2064        ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16)          64          ['dense_13[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16)           0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 4)            68          ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 4)           16          ['dense_14[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 4)            0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 1)            5           ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 256,908,329\n",
            "Trainable params: 256,907,521\n",
            "Non-trainable params: 808\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1f08cb06",
      "metadata": {
        "id": "1f08cb06"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.0005), loss = \"binary_crossentropy\", metrics = [tf.metrics.BinaryAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e31e0c4e",
      "metadata": {
        "id": "e31e0c4e",
        "outputId": "06239404-7693-4ec1-ac0a-d76cedd81237",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "50/50 [==============================] - 24s 329ms/step - loss: 1.1652 - binary_accuracy: 0.4986 - val_loss: 1.1158 - val_binary_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 16s 315ms/step - loss: 1.1353 - binary_accuracy: 0.5005 - val_loss: 1.1032 - val_binary_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 14s 289ms/step - loss: 1.1096 - binary_accuracy: 0.5044 - val_loss: 1.0919 - val_binary_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 14s 287ms/step - loss: 1.0840 - binary_accuracy: 0.5148 - val_loss: 1.0755 - val_binary_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 14s 288ms/step - loss: 1.0635 - binary_accuracy: 0.5120 - val_loss: 1.0568 - val_binary_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 14s 288ms/step - loss: 1.0455 - binary_accuracy: 0.5173 - val_loss: 1.0390 - val_binary_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 1.0192 - binary_accuracy: 0.5411 - val_loss: 1.0203 - val_binary_accuracy: 0.4992\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 14s 287ms/step - loss: 0.9983 - binary_accuracy: 0.5414 - val_loss: 1.0013 - val_binary_accuracy: 0.5016\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 14s 285ms/step - loss: 0.9817 - binary_accuracy: 0.5577 - val_loss: 0.9807 - val_binary_accuracy: 0.5227\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 15s 294ms/step - loss: 0.9620 - binary_accuracy: 0.5639 - val_loss: 0.9574 - val_binary_accuracy: 0.5516\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 14s 291ms/step - loss: 0.9420 - binary_accuracy: 0.5733 - val_loss: 0.9344 - val_binary_accuracy: 0.5969\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 16s 316ms/step - loss: 0.9238 - binary_accuracy: 0.5827 - val_loss: 0.9130 - val_binary_accuracy: 0.6242\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 14s 289ms/step - loss: 0.9045 - binary_accuracy: 0.5905 - val_loss: 0.8932 - val_binary_accuracy: 0.6172\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 15s 292ms/step - loss: 0.8891 - binary_accuracy: 0.5975 - val_loss: 0.8693 - val_binary_accuracy: 0.6445\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 14s 287ms/step - loss: 0.8712 - binary_accuracy: 0.6014 - val_loss: 0.8490 - val_binary_accuracy: 0.6469\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 16s 328ms/step - loss: 0.8516 - binary_accuracy: 0.6266 - val_loss: 0.8278 - val_binary_accuracy: 0.6500\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 14s 288ms/step - loss: 0.8341 - binary_accuracy: 0.6405 - val_loss: 0.8124 - val_binary_accuracy: 0.6625\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 14s 287ms/step - loss: 0.8155 - binary_accuracy: 0.6531 - val_loss: 0.7932 - val_binary_accuracy: 0.6828\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.7924 - binary_accuracy: 0.6614 - val_loss: 0.7740 - val_binary_accuracy: 0.6828\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 16s 329ms/step - loss: 0.7744 - binary_accuracy: 0.6755 - val_loss: 0.7569 - val_binary_accuracy: 0.6750\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 17s 332ms/step - loss: 0.7504 - binary_accuracy: 0.6922 - val_loss: 0.7410 - val_binary_accuracy: 0.6906\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 15s 293ms/step - loss: 0.7352 - binary_accuracy: 0.6920 - val_loss: 0.7310 - val_binary_accuracy: 0.6812\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 14s 284ms/step - loss: 0.7152 - binary_accuracy: 0.7020 - val_loss: 0.7376 - val_binary_accuracy: 0.6820\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 14s 290ms/step - loss: 0.6900 - binary_accuracy: 0.7236 - val_loss: 0.7154 - val_binary_accuracy: 0.6805\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 17s 333ms/step - loss: 0.6766 - binary_accuracy: 0.7270 - val_loss: 0.7028 - val_binary_accuracy: 0.6828\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 14s 288ms/step - loss: 0.6586 - binary_accuracy: 0.7309 - val_loss: 0.7082 - val_binary_accuracy: 0.6844\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 15s 292ms/step - loss: 0.6356 - binary_accuracy: 0.7497 - val_loss: 0.6961 - val_binary_accuracy: 0.6977\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 14s 290ms/step - loss: 0.6221 - binary_accuracy: 0.7592 - val_loss: 0.7052 - val_binary_accuracy: 0.6930\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 16s 327ms/step - loss: 0.6067 - binary_accuracy: 0.7628 - val_loss: 0.7159 - val_binary_accuracy: 0.6844\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 15s 295ms/step - loss: 0.5828 - binary_accuracy: 0.7778 - val_loss: 0.7156 - val_binary_accuracy: 0.6727\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 14s 289ms/step - loss: 0.5803 - binary_accuracy: 0.7728 - val_loss: 0.6802 - val_binary_accuracy: 0.7117\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 14s 290ms/step - loss: 0.5619 - binary_accuracy: 0.7837 - val_loss: 0.6868 - val_binary_accuracy: 0.6984\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 15s 293ms/step - loss: 0.5421 - binary_accuracy: 0.7961 - val_loss: 0.6955 - val_binary_accuracy: 0.6969\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 17s 345ms/step - loss: 0.5409 - binary_accuracy: 0.7881 - val_loss: 0.7046 - val_binary_accuracy: 0.6852\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 14s 290ms/step - loss: 0.5339 - binary_accuracy: 0.7969 - val_loss: 0.6952 - val_binary_accuracy: 0.7141\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 14s 287ms/step - loss: 0.5058 - binary_accuracy: 0.8141 - val_loss: 0.6926 - val_binary_accuracy: 0.7094\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 16s 317ms/step - loss: 0.5027 - binary_accuracy: 0.8169 - val_loss: 0.6825 - val_binary_accuracy: 0.7063\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.4957 - binary_accuracy: 0.8123 - val_loss: 0.7110 - val_binary_accuracy: 0.6906\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 17s 339ms/step - loss: 0.4870 - binary_accuracy: 0.8178 - val_loss: 0.7047 - val_binary_accuracy: 0.6867\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 14s 291ms/step - loss: 0.4838 - binary_accuracy: 0.8169 - val_loss: 0.6909 - val_binary_accuracy: 0.7047\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 15s 294ms/step - loss: 0.4552 - binary_accuracy: 0.8364 - val_loss: 0.7105 - val_binary_accuracy: 0.7000\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 17s 349ms/step - loss: 0.4532 - binary_accuracy: 0.8347 - val_loss: 0.7616 - val_binary_accuracy: 0.6906\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 14s 291ms/step - loss: 0.4470 - binary_accuracy: 0.8367 - val_loss: 0.7441 - val_binary_accuracy: 0.6859\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 15s 294ms/step - loss: 0.4435 - binary_accuracy: 0.8402 - val_loss: 0.7392 - val_binary_accuracy: 0.6852\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 14s 291ms/step - loss: 0.4191 - binary_accuracy: 0.8517 - val_loss: 0.7579 - val_binary_accuracy: 0.6781\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 17s 343ms/step - loss: 0.4179 - binary_accuracy: 0.8512 - val_loss: 0.7932 - val_binary_accuracy: 0.6797\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 15s 297ms/step - loss: 0.4153 - binary_accuracy: 0.8552 - val_loss: 0.7415 - val_binary_accuracy: 0.6953\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 15s 295ms/step - loss: 0.3975 - binary_accuracy: 0.8584 - val_loss: 0.7575 - val_binary_accuracy: 0.6906\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 14s 285ms/step - loss: 0.4100 - binary_accuracy: 0.8519 - val_loss: 0.7494 - val_binary_accuracy: 0.6977\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 15s 298ms/step - loss: 0.3944 - binary_accuracy: 0.8634 - val_loss: 0.7890 - val_binary_accuracy: 0.6781\n"
          ]
        }
      ],
      "source": [
        "loss_history = model.fit(siam_gen([df[\"clean_text\"], df[\"reason\"]], 128), \n",
        "                         validation_data = siam_gen([df_test[\"clean_text\"], df_test[\"reason\"]], 128),\n",
        "                         steps_per_epoch=50, validation_steps=10, epochs = 50, \n",
        "                         verbose = True, use_multiprocessing=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import brier_score_loss as brier_loss\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import log_loss"
      ],
      "metadata": {
        "id": "KknErpHnsoOK"
      },
      "id": "KknErpHnsoOK",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "4e5cf29b",
      "metadata": {
        "id": "4e5cf29b",
        "outputId": "fe14c5ba-9cc1-4b06-e90a-efdfa8ada8cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.942310037809489"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "y_preds = model.predict([df['clean_text'], df['reason']])\n",
        "accuracy(df['label'], y_preds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = (y_preds >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "75DCUIxLtDaT"
      },
      "id": "75DCUIxLtDaT",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Brier Loss                       : \", brier_loss(df['label'], y_preds))\n",
        "print(\"Precision Score                  : \", precision_score(df['label'], y_hat))\n",
        "print(\"Recall Score                     : \", recall_score(df['label'], y_hat))\n",
        "print(\"F1 Score                         : \", f1_score(df['label'], y_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIukxt3Jsl6s",
        "outputId": "1faccc63-3cdc-4bbb-85d4-06be858fc7c7"
      },
      "id": "dIukxt3Jsl6s",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brier Loss                       :  0.0549892452622003\n",
            "Precision Score                  :  1.0\n",
            "Recall Score                     :  0.942310037809489\n",
            "F1 Score                         :  0.9702982731554161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b0dd41b8",
      "metadata": {
        "id": "b0dd41b8",
        "outputId": "5e91d3cf-a6d8-4934-9116-f7ee9ba70dc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5422222222222223"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "y_preds = model.predict([df_test['clean_text'], df_test['reason']])\n",
        "accuracy(df_test['label'], y_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "20d2fa6b",
      "metadata": {
        "id": "20d2fa6b"
      },
      "outputs": [],
      "source": [
        "y_hat = (y_preds >= 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "d1fed3c5",
      "metadata": {
        "id": "d1fed3c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c86fd55-1909-48d9-9ada-a79736f6643d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brier Loss                       :  0.3241015325028808\n",
            "Precision Score                  :  0.39792008757526\n",
            "Recall Score                     :  0.7267577474175275\n",
            "F1 Score                         :  0.5142655034190049\n",
            "Roc AUC Score                    :  0.616703833622387\n",
            "BCE Loss                         :  0.9542487061606952\n"
          ]
        }
      ],
      "source": [
        "print(\"Brier Loss                       : \", brier_loss(df_test['label'], y_preds))\n",
        "print(\"Precision Score                  : \", precision_score(df_test['label'], y_hat))\n",
        "print(\"Recall Score                     : \", recall_score(df_test['label'], y_hat))\n",
        "print(\"F1 Score                         : \", f1_score(df_test['label'], y_hat))\n",
        "print(\"Roc AUC Score                    : \", roc_auc_score(df_test['label'], y_preds))\n",
        "print(\"BCE Loss                         : \", log_loss(df_test['label'], y_preds))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "816cf323",
      "metadata": {
        "id": "816cf323"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e3e2d20",
      "metadata": {
        "id": "2e3e2d20"
      },
      "outputs": [],
      "source": [
        "Brier Loss                       :  0.3203359289886762\n",
        "Precision Score                  :  0.39153871283894154\n",
        "Recall Score                     :  0.7987337554148617\n",
        "F1 Score                         :  0.5254850378165077\n",
        "Roc AUC Score                    :  0.6452798225451215\n",
        "BCE Loss                         :  0.9062959283337825\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d02e67",
      "metadata": {
        "id": "65d02e67"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mlAsgmt",
      "language": "python",
      "name": "mlasgmt"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "useCONCT -.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}